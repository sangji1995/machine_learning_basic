import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#붓꽃 데이터 불러오기
df=pd.read_csv('https://archive.ics.uci.edu/ml/''machine-learning-databases/iris/iris.data',header=None)

X=df.iloc[0:100,[0,2]].values #앞 100개 샘플의 컬럼0(꽃받침 길이)과 칼럼2(꽃잎) iloc위치 지정 0~99번째 까지 가져오겠다 길이 값들만

y=df.iloc[0:100,4].values #앞 100개 샘플의 정답값(꽃종류)을 가지고 옴

y=np.where(y=='lris-setosa',-1,1) #값이 lris-setosa이면 -1, 아니면 1로 표기 
 

#adaline구현

class AdalineGD(object):
    
    def __init__(self, eta=0.01,n_iter=50,random_state=1): #eta=lr 학습률
        self.eta=eta #스텝사이즈(학습률, learning rate)
        self.n_iter=n_iter #가중치 업데이트 반복 회수
        self.random_state =random_state #난수 발생기 시드
        
    def net_input(self,X): #입력의 선형조합(z)을 출력
        return np.dot(X,self.w_[1:])+self.w_[0] #dot으로 인해 x와 w가 1부터 계속 곱해진다 
    
    def activation(self,X): #활성화 함수
        return X    #현재는 입력을 그대로 출력함
    
    def predict(self,X): #추론 함수. 입력 선형조합(z) -> 활성화함수 -> 임계함수 -> 최종 추론
        return np.where(self.activation(self.net_input(X))>=0.0,1,-1)
    
    #학습 함수
    def fit(self,X,y):
        #x:학습 데이터
        #y:정답값(레이블)
        #
        regn=np.random.RandomState(self.random_state) #난수 발생기 생성 가중치 초기화 랜덤한 수로 채움
        self.w_=regn.normal(loc=0.0, scale=0.01, size=1+X.shape[1]) #가중치 랜덤 초기화 x.shape 입력 개수만큼 필요 (+1)는 w0다
        self.cost_=[] #반복에 따른 오차(비용)값 저장 변수 오차값 누적 저장
        
        for i in range(self.n_iter): #반복 학습(가중치 업데이트) 
            net_input=self.net_input(X) #입력데이터의 선형조합(z)
            output=self.activation(net_input) #활성화 함수 출력
            errors=(y-output) #정답과 차이 계산 퍼셉트론은 오차값을 임계값에서 비교 아다는 위에 활성함수에서 나온 값들로 비교 
            self.w_[1:]+=self.eta*X.T.dot(errors) #경사하강법으로 가중치 업데이트 오른쪽 미분값 1~m까지 x입력값이 존재
            self.w_[0]+=self.eta*errors.sum() #x_0=1을 가정, 그에 맞게 w_0업데이트 x입력값이 없어서 에러값을 다 더한걸로 
            cost=(errors**2).sum()/2.0 #오차함수값 계산 
            self.cost_.append(cost) #오차값 저장 변수에 현재 오차값 추가 가중치 업뎃됐다.
        return self    
            
fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,4)) #subplot 그림큰거 하나 그리고 여러개 그래프  행1 열2 

ada1=AdalineGD(n_iter=10,eta=0.01).fit(X,y) #Ada1 입력값 fit으로 나타냈지
ax[0].plot(range(1,len(ada1.cost_)+1),ada1.cost_,marker='o')
ax[0].set_xlabel('iterations')
ax[0].set_ylabel('Sum-squared-error')
ax[0].set_title('adaline-learning rate 0.01')

ada2=AdalineGD(n_iter=1000,eta=0.0001).fit(X,y) #Adaline2
ax[1].plot(range(1,len(ada2.cost_)+1),ada2.cost_, marker='o')
ax[1].set_xlabel('iterations')
ax[1].set_ylabel('Sum-squared-error')
ax[1].set_title('adaline-learning rate 0.0001')

plt.show()
